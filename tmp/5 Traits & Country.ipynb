{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Traits Localized Model\n",
    "> In psychological trait theory, the Big Five personality traits, also known as the five-factor model (FFM) and the OCEAN model, is a suggested taxonomy, or grouping, for personality traits, developed from the 1980s onwards. When factor analysis (a statistical technique) is applied to personality survey data, some words used to describe aspects of personality are often applied to the same person. For example, someone described as conscientious is more likely to be described as \"always prepared\" rather than \"messy\". This theory is based therefore on semantic associations between words and not on neuropsychological experiments. This theory uses descriptors of common language and suggests five broad dimensions commonly used to describe the human personality and psyche.\n",
    "The theory identifies five factors:\n",
    "> - openness to experience (inventive/curious vs. consistent/cautious)\n",
    "> - conscientiousness (efficient/organized vs. easy-going/careless)\n",
    "> - extroversion (outgoing/energetic vs. solitary/reserved)\n",
    "> - agreeableness (friendly/compassionate vs. challenging/detached)\n",
    "> - neuroticism (sensitive/nervous vs. secure/confident)\n",
    "\n",
    "[Big Five personality traits](https://en.wikipedia.org/wiki/Big_Five_personality_traits)\n",
    "\n",
    "The questionare consists of 50 statements, on which person is asked to anwser (on 1 to 5 scale), how much ge agrees on the statement. The statements are divided into 5 groups assosited with the traits. On top of that, we have informations about the place, where survey took place. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple bayesian interpretation\n",
    "![](images/5_traits_model_localized.svg)\n",
    "\n",
    "In the Big 5 Peronality traits model, we assume that, that user personality can be described by 5 dimensional, orthogonal vector, where each dimension is orthogonal to each other (at least in respect to quiz questions). \n",
    "\n",
    "## Distributions\n",
    "Each trait will be modeled as a Beta distribution, with \\\\(\\alpha\\\\) and \\\\(\\beta\\\\) conditioned on country. ie:\n",
    "\\begin{equation}\n",
    "Openness \\sim Beta(\\alpha=\\alpha_{openness}, \\beta = \\beta_{openness})\n",
    "\\end{equation}\n",
    "\n",
    "At last, we assume that each statement agreement comes from a binomial dristribution, where n=4, and p=Trait, eg.\n",
    "\n",
    "\\begin{equation}\n",
    "OPN_i^* \\sim Binomial(n=4, p=Openness_c) + 1\n",
    "\\end{equation}\n",
    "\n",
    "We do it for every question, for every sample. This way, we can interpret trait as measure of likelihood, that someone would agree with the statement (ie. we transform a 5-scale problem into binary problem, so that the trait can be interpreted as probability of someone agreeing with the question. The +1 comes from the fact, that opinions range from 1 - 5, rather that 0 - 4. The star in the notation means a standarized anwser. Some statements are reverse (ie. I don't like people in extraversion trait). By standarized statement we mean, that for such cases we flip the question into agreeing form (I like people) and change the anwser as following\n",
    "\\begin{equation}\n",
    "OPN_i^* = 6 - OPN_i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from common import N_COUNTIRES, load_joint, empty_df, positive_correlation, QUESTIONS\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import torch.distributions.constraints as const\n",
    "import pyro.poutine as poutine\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigFiveModel:\n",
    "    # Parameters of prior trait distributions\n",
    "    ALPHA_PRIOR = 1.0\n",
    "    BETA_PRIOR = 1.0\n",
    "    \n",
    "    def __init__(self):           \n",
    "        initial_obs = {\n",
    "            **{\n",
    "                key: []\n",
    "                for key in QUESTIONS.keys()\n",
    "            },\n",
    "            'country': []\n",
    "        }\n",
    "\n",
    "        self._observations = pd.DataFrame(initial_obs)\n",
    "        self._mask = np.zeros((0, 51))\n",
    "        \n",
    "        self.fitted = False\n",
    "        \n",
    "        \n",
    "    def _add_user(self, user: str):\n",
    "        initial_obs = {\n",
    "            **{\n",
    "                key: 0\n",
    "                for key in QUESTIONS.keys()\n",
    "            },\n",
    "            'country': 0\n",
    "        }\n",
    "        \n",
    "        self._observations = pd.concat([\n",
    "            self._observations, \n",
    "            pd.DataFrame(initial_obs, index=[user])\n",
    "        ])\n",
    "        self._mask = np.concatenate([\n",
    "            self._mask,\n",
    "            np.zeros((1, 51))\n",
    "        ])\n",
    "        \n",
    "    \n",
    "    def model(self, anwsers, countries, anwser_mask = None, country_mask = None):                 \n",
    "        n_samples = anwsers.shape[-1]\n",
    "        \n",
    "        trait_alpha_priors = pyro.param('trait_alpha_priors', self.ALPHA_PRIOR * torch.ones(5, N_COUNTIRES), constraint=const.positive)\n",
    "        trait_beta_priors = pyro.param('trait_beta_priors', self.BETA_PRIOR * torch.ones(5, N_COUNTIRES), constraint=const.positive)\n",
    "\n",
    "        # Don't fit priors in inference stage\n",
    "        if self.fitted:\n",
    "            trait_alpha_priors = torch.tensor(self.prior_alphas)\n",
    "            trait_beta_priors = torch.tensor(self.prior_betas)\n",
    "        \n",
    "        with pyro.plate(\"person\", n_samples):\n",
    "            country = countries\n",
    "            if country_mask is not None:\n",
    "                # Make prior a non-trainable uniform\n",
    "                country = pyro.sample('country', dist.Categorical(torch.ones(N_COUNTIRES)).mask(country_mask))\n",
    "\n",
    "                # Overwire countires that are observed\n",
    "                country = countries * country_mask + (country * (1.0 - country_mask))\n",
    "                            \n",
    "            with pyro.plate('traits', 5):\n",
    "                # Prior on traits will depend on country. This way we can use country to reinforce our predictions with better prior,\n",
    "                # which is not biased by imbalanced country\n",
    "                trait = pyro.sample('trait', dist.Beta(trait_alpha_priors[:, country.long()], trait_beta_priors[:, country.long()]))\n",
    "\n",
    "                with pyro.plate(\"question\", 10):\n",
    "                    # assume uniform\n",
    "                    distribution = dist.Binomial(4, trait)\n",
    "                    if anwser_mask != None:\n",
    "                        distribution = distribution.mask(anwser_mask)\n",
    "                    \n",
    "                    anwser = pyro.sample('anwser', distribution, obs=anwsers)\n",
    "\n",
    "                    return anwser, trait\n",
    "                               \n",
    "    \n",
    "    def train_guide(self, anwsers, countries, anwser_mask = None, country_mask = None):   \n",
    "        n_samples = anwsers.shape[-1]\n",
    "                \n",
    "        # Not reeeeeeeeeaaaaaaaaally important, but hey - its a guide and posterior must fit :)\n",
    "        trait_alphas = pyro.param('trait_alphas_train', self.ALPHA_PRIOR * torch.ones(5, n_samples), constraint=const.positive)\n",
    "        trait_betas = pyro.param('trait_betas_train', self.BETA_PRIOR * torch.ones(5, n_samples), constraint=const.positive)\n",
    "        \n",
    "        with pyro.plate(\"person\", n_samples):\n",
    "            with pyro.plate('traits', 5):\n",
    "                trait = pyro.sample('trait', dist.Beta(trait_alphas, trait_betas))\n",
    "                    \n",
    "                \n",
    "    def infer_guide(self, anwsers, countries, anwser_mask = None, country_mask = None):  \n",
    "        n_samples = anwsers.shape[-1]\n",
    "        \n",
    "        countries_probs = pyro.param('country_probs', torch.ones(N_COUNTIRES) / N_COUNTIRES, constraint = const.simplex)\n",
    "\n",
    "        with pyro.plate(\"person\", len(self._observations)):\n",
    "            \n",
    "            # Make prior a non-trainable uniform\n",
    "            country = pyro.sample('country', dist.Categorical(logits=torch.log(countries_probs)).mask(country_mask))\n",
    "\n",
    "            # Overwire countires that are observed\n",
    "            country = countries * country_mask + (country * (1.0 - country_mask))\n",
    "            \n",
    "            with pyro.plate('traits', 5):\n",
    "                trait_alphas = pyro.param('trait_alphas', self.ALPHA_PRIOR * torch.ones(5, N_COUNTIRES))\n",
    "                trait_betas = pyro.param('trait_betas', self.BETA_PRIOR * torch.ones(5, N_COUNTIRES))\n",
    "\n",
    "                trait = pyro.sample('trait', dist.Beta(trait_alphas[:, country.long()], trait_betas[:, country.long()]))   \n",
    "\n",
    "                \n",
    "    def observe(self, user: str, x: dict) -> None:        \n",
    "        if user not in self._observations.index:\n",
    "            self._add_user(user)\n",
    "        \n",
    "        for key, value in x.items():\n",
    "            if key != 'country':\n",
    "                # Filp value if it has negative corelation \n",
    "                if not positive_correlation(key):\n",
    "                    value = 6 - value\n",
    "                \n",
    "                # We map values 1 - 5 into 0 - 4\n",
    "                self._observations.loc[user, key] = np.clip(value - 1.0, 0, 4)\n",
    "                self._mask[\n",
    "                    self._observations.index.get_loc(user),\n",
    "                    self._observations.columns.get_loc(key)\n",
    "                ] = 1\n",
    "            else:\n",
    "                self._observations.loc[user, key] = value\n",
    "                \n",
    "    \n",
    "    def fit_prior(self, data, num_steps = 5_000):            \n",
    "        pyro.clear_param_store()\n",
    "        pyro.enable_validation(True)\n",
    "        svi = pyro.infer.SVI(model=self.model,\n",
    "                             guide=self.train_guide,\n",
    "                             optim=pyro.optim.Adam({\"lr\": 1e-2}),\n",
    "                             loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "        anwsers = torch.tensor(\n",
    "            np.clip(data.drop('country', axis=1).values.reshape(-1, 5, 10).transpose([2, 1, 0]) - 1.0, 0.0, 4.0)\n",
    "        )\n",
    "        \n",
    "        country = torch.tensor(\n",
    "            data['country'].values.reshape(-1)\n",
    "        )\n",
    "                \n",
    "        losses = []\n",
    "        for t in tqdm(range(num_steps)):\n",
    "            losses.append(svi.step(anwsers, country))\n",
    "            \n",
    "        # Freeze priors\n",
    "        self.fitted = True\n",
    "        self.prior_alphas = pyro.param('trait_alpha_priors').detach().numpy()\n",
    "        self.prior_betas = pyro.param('trait_beta_priors').detach().numpy()\n",
    "        \n",
    "\n",
    "        plt.plot(losses)\n",
    "        plt.title(\"ELBO\")\n",
    "        plt.xlabel(\"step\")\n",
    "        plt.ylabel(\"loss\")\n",
    "                \n",
    "                \n",
    "    def infer(self, num_steps = 1_000, lr=5e-2):\n",
    "        anwser_mask = torch.tensor(self._mask[:, :50].reshape(-1, 5, 10).transpose([2, 1, 0]))\n",
    "        country_mask = torch.tensor(self._mask[:, 50].reshape(-1))\n",
    "        \n",
    "        anwsers = torch.tensor(\n",
    "            self._observations.drop('country', axis=1).values.reshape(-1, 5, 10).transpose([2, 1, 0])\n",
    "        )\n",
    "        \n",
    "        country = torch.tensor(\n",
    "            self._observations['country'].values.reshape(-1)\n",
    "        )\n",
    "        \n",
    "        pyro.clear_param_store()\n",
    "        pyro.enable_validation(True)\n",
    "        svi = pyro.infer.SVI(model=self.model,\n",
    "                             guide=self.infer_guide,\n",
    "                             optim=pyro.optim.Adam({\"lr\": lr}),\n",
    "                             loss=pyro.infer.TraceGraph_ELBO())\n",
    "\n",
    "        losses = []\n",
    "        for t in tqdm(range(num_steps)):\n",
    "            losses.append(svi.step(anwsers, country, anwser_mask, country_mask))\n",
    "\n",
    "        plt.plot(losses)\n",
    "        plt.title(\"ELBO\")\n",
    "        plt.xlabel(\"step\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        \n",
    "    def sample(self, n_samples):\n",
    "        return pyro.infer.Predictive(self.model, guide=self.traits_guide, num_samples=n_samples)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = load_joint().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "contry_encoder = OrdinalEncoder()\n",
    "data_1['country'] = contry_encoder.fit_transform(data_1['country'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:04<00:00, 77.77it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyro.enable_validation(True)\n",
    "model = BigFiveModel()\n",
    "model.fit_prior(data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference of latents for dataset colected via survey\n",
    "We (and our friends) did a Five Traits psychological test ourselves. Here we present infered distributions over latent variables for these anwsers to statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/test_results.csv\")\n",
    "\n",
    "users = {}\n",
    "for _, row in data.iterrows():\n",
    "    name = row[1]\n",
    "    users[name] = {\n",
    "        key: row.values[2 + i]\n",
    "        for i, key in enumerate(QUESTIONS.keys())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 507/2000 [00:02<00:07, 190.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-264-5536c196b26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-254-ce67f2745757>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, num_steps)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manwsers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manwser_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/infer/tracegraph_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mbaselines\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malso\u001b[0m \u001b[0mconstructed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdifferentiated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0melbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_and_surrogate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mtorch_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurrogate_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/infer/tracegraph_elbo.py\u001b[0m in \u001b[0;36m_loss_and_surrogate_loss\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0msurrogate_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_and_surrogate_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/infer/tracegraph_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \"\"\"\n\u001b[1;32m    224\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m--> 225\u001b[0;31m             \"dense\", self.max_plate_nesting, model, guide, args, kwargs)\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[0;32m---> 48\u001b[0;31m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mcheck_model_guide_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/pyro/poutine/messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_context_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-254-ce67f2745757>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self, anwsers, countries, anwser_mask, country_mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;31m# Prior on traits will depend on country. This way we can use country to reinforce our predictions with better prior,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# which is not biased by imbalanced country\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mtrait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trait'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrait_alpha_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrait_beta_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/torch/distributions/beta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, concentration1, concentration0, validate_args)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mconcentration1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mconcentration1_concentration0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dirichlet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirichlet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration1_concentration0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dirichlet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/torch/distributions/dirichlet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, concentration, validate_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDirichlet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projekty/puma/venv/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for user, observations in users.items():\n",
    "    model.observe(user, observations)\n",
    "model.infer(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01736466, 0.01686192, 0.01662194, 0.01695778, 0.01602201,\n",
       "       0.01797888, 0.0184483 , 0.01787258, 0.01829689, 0.01698616,\n",
       "       0.01581833, 0.01735384, 0.01712149, 0.01812812, 0.01651926,\n",
       "       0.01553261, 0.01612105, 0.01679028, 0.01689042, 0.01786496,\n",
       "       0.01728389, 0.01719488, 0.01617063, 0.01508683, 0.01800878,\n",
       "       0.01718871, 0.01760238, 0.01757941, 0.01769511, 0.01845183,\n",
       "       0.01618276, 0.01623814, 0.0176825 , 0.01759106, 0.0182484 ,\n",
       "       0.01706097, 0.01738195, 0.01854915, 0.0180332 , 0.01722343,\n",
       "       0.01651153, 0.01742065, 0.01799831, 0.01719332, 0.0161303 ,\n",
       "       0.01870553, 0.01716016, 0.0167863 , 0.01694542, 0.01734252,\n",
       "       0.01713439, 0.01654059, 0.01709703, 0.01860971, 0.0158019 ,\n",
       "       0.017745  , 0.01917801, 0.01769367], dtype=float32)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.param('country_probs').detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent trait distribution\n",
    "Display a trait probability distribution for each user in the database, based on their statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.sample(1000)['trait'].detach().numpy().reshape(1000, 5, -1).transpose([2, 0, 1])\n",
    "\n",
    "dfs = []\n",
    "for i, user in enumerate(users.keys()):\n",
    "    realistations = x[i, :, :]\n",
    "    \n",
    "    df = pd.DataFrame( {\n",
    "        name: realistations[:, i]\n",
    "        for i, name in enumerate([\"extroversion\", \"neuroticism\", \"agreeableness\", \"conscientiousness\", \"openness\"])\n",
    "    })\n",
    "\n",
    "    df = pd.melt(df, var_name=\"Trait\")\n",
    "    df['user'] = user[:5]\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "data_frame = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "g = sns.FacetGrid(data=data_frame, row=\"user\", col=\"Trait\", hue=\"Trait\")\n",
    "g.map(sns.distplot, \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
